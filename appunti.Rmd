---
title: "appunti"
output: html_document
date: "2025-01-15"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Fixed transformations

Here we discuss tests that use the full group of transformations.

### Basic permutation test

Let $X$ be data taking values in a sample space $\mathcal{X}$. Let $G$ be a finite set of transformations $g : \mathcal{X} \rightarrow \mathcal{X}$, such that $G$ is a group with respect to the operation of composition of transformations. This means that $G$ satisfies the following three properties: $G$ contains an identity element (the map $x \mapsto x$); every element of $G$ has an inverse in $G$; for all $a_1, a_2 \in G$, $a_1 \circ a_2 \in G$. This assumption of a group structure for $G$ is fundamental throughout the paper, since it ensures that $Gg = G$ for all $g \in G$, i.e. that the set $G$ is permutation invariant.

Considering a general group of transformations rather than only permutations is useful, since in many practical situations the group consists of, for example, rotations [@Langsrud2005; @Solari2014] or maps that multiply part of the data by $-1$ [@Pesarin2010]. We write $g(X)$ as $gX$. Consider any test statistic $T : \mathcal{X} \rightarrow \mathbb{R}$. Throughout this paper, we are concerned with testing the following null hypothesis of permutation invariance.

\begin{definition}
Let $H_p$ be any null hypothesis which implies that the joint distribution of the test statistics $T(gX)$, $g \in G$, is invariant under all transformations in $G$ of $X$. That is, writing $G = \{a_1, \ldots, a_{\#G}\}$, under $H_p$
\[
(T(a_1X), \ldots, T(a_{\#G}X)) \overset{d}{=} (T(a_1gX), \ldots, T(a_{\#G}gX))
\]
for all $g \in G$.
\end{definition}

Note that \eqref{eq:null_hyp} holds in particular when for all $g \in G$
\[
X \overset{d}{=} gX.
\]

Composite null hypotheses are usually not of the form $H_p$, but for specific scenarios, properties of tests of such hypotheses can be established using results in this paper.

The most basic permutation test rejects $H_p$ when $T(X) > T^{(k)}(X)$, where
\[
T^{(1)}(X) \leq \cdots \leq T^{(\#G)}(X)
\]
are the sorted test statistics $T(gX)$, $g \in G$, and $k = \lfloor(1 - \alpha)\#G\rfloor$ with $\alpha \in [0, 1)$. As is known and stated in the following theorem, this test has level at most $\alpha$.

\begin{theorem}
Under $H_p$, $\mathbb{P}\{T(X) > T^{(k)}(X)\} \leq \alpha$.
\end{theorem}

We now give two proofs: a conditioning-based approach and an approach without conditioning. Both approaches are more or less known. The conditioning-based proof is similar to that in @Pesarin2015, but the setting is more general. For each $x \in \mathcal{X}$, define $\mathcal{O}_x$ to be the orbit of $x$, which is the set $\{gx : g \in G\} \subseteq \mathcal{X}$.

\begin{proof}[Conditioning-based proof]
Let $A = \{x \in \mathcal{X} : T(x) > T^{(k)}(x)\}$ be the set of elements of the sample space that lead to rejection. Suppose $H_p$ holds. By the group structure, $Gg = G$ for all $g \in G$. Consequently, $T^{(k)}(gX) = T^{(k)}(X)$ for all $g \in G$. Thus, $\#{g \in G : gX \in A} = \#{g \in G : T(gX) > T^{(k)}(gX)\} = \#{g \in G : T(gX) > T^{(k)}(X)\} \leq \alpha\#G$.

Endow the space of orbits with the $\sigma$-algebra that it inherits from the $\sigma$-algebra on $\mathcal{X}$. Analogously to the proof of Theorem 15.2.2 in @Lehmann2005, we obtain
\[
\mathbb{P}(X \in A | \mathcal{O}_X) = \frac{1}{\#G}\#{g \in G : gX \in A}.
\]
By the argument above, this is bounded by $\alpha$. Hence,
\[
\mathbb{P}(X \in A) = \mathbb{E}\{\mathbb{P}(X \in A | \mathcal{O}_X)\} \leq \alpha
\]
as was to be shown.
\end{proof}

We now state a different proof without conditioning. A similar proof can be found in @Hoeffding1952 and @Lehmann2005 (p. 634).

\begin{proof}[Direct proof]
By the group structure, $Gg = G$ for all $g \in G$. Hence, $T^{(k)}(gX) = T^{(k)}(X)$ for all $g \in G$. Let $h$ have the uniform distribution on $G$. Then, under $H_p$, the rejection probability is
\[
\mathbb{P}\{T(X) > T^{(k)}(X)\} = \mathbb{P}\{T(hX) > T^{(k)}(hX)\} = \mathbb{P}\{T(hX) > T^{(k)}(X)\}.
\]
The first equality follows from the null hypothesis, and the second equality holds since $T^{(k)}(X) = T^{(k)}(hX)$. Since $h$ is uniform on $G$, the above probability equals
\[
\mathbb{E}\left[\frac{1}{\#G} \cdot \#{g \in G : T(gX) > T^{(k)}(X)\}\right] \leq \alpha,
\]
as was to be shown.
\end{proof}

The test of Theorem 1 is not always exact. When the data are discrete, then the basic permutation test is often slightly conservative, due to a nonzero probability of tied values in $\mathcal{X}$. Under the following condition, which is often satisfied for continuous data, but usually not for discrete data, the test is exact for certain values of $\alpha$.

\begin{condition}
There is a partition $\{G_1, \ldots, G_m\}$ of $G$ with $\mathrm{id} \in G_1$ and $\#G_1 = \cdots = \#G_m$, such that under $H_p$ with probability 1 for all $g, g' \in G$, $T(gX) = T(g'X)$ if and only if $g$ and $g'$ are in the same set $G_i$.
\end{condition}

\begin{proposition}
Under Condition 1, the test of Theorem 1 is exact if and only if $\alpha \in \{0, 1/m, \ldots, (m - 1)/m\}$.
\end{proposition}

The proof of this result is analogous to the proof of Theorem 1. As an example where Condition 1 holds, consider a randomized trial where $X \in \mathbb{R}^{2n}$




# nuovo

\section{Fixed transformations}

\subsection{Basic permutation test}

Let $X$ be data taking values in a sample space $\mathcal{X}$. Let $G$ be a finite set of transformations $g : \mathcal{X} \rightarrow \mathcal{X}$, such that $G$ is a group with respect to the operation of composition of transformations. This means that $G$ satisfies the following three properties: $G$ contains an identity element (the map $x \mapsto x$); every element of $G$ has an inverse in $G$; for all $a_1, a_2 \in G$, $a_1 \circ a_2 \in G$. This assumption of a group structure for $G$ is fundamental throughout the paper, since it ensures that $Gg = G$ for all $g \in G$, i.e. that the set $G$ is permutation invariant.

Considering a general group of transformations rather than only permutations is useful, since in many practical situations the group consists of, for example, rotations \citep{Langsrud2005, Solari2014} or maps that multiply part of the data by $-1$ \citep{Pesarin2010}. We write $g(X)$ as $gX$. Consider any test statistic $T : \mathcal{X} \rightarrow \mathbb{R}$. Throughout this paper, we are concerned with testing the following null hypothesis of permutation invariance.

\begin{definition}
Let $H_p$ be any null hypothesis which implies that the joint distribution of the test statistics $T(gX)$, $g \in G$, is invariant under all transformations in $G$ of $X$. That is, writing $G = \{a_1, \ldots, a_{#G}\}$, under $H_p$
\[
\left(T(a_1X), \ldots, T(a_{#G}X)\right) \overset{d}{=} \left(T(a_1gX), \ldots, T(a_{#G}gX)\right)
\]
for all $g \in G$.
\end{definition}

Note that \eqref{eq:null_hypothesis} holds in particular when for all $g \in G$
\[
X \overset{d}{=} gX.
\]

Composite null hypotheses are usually not of the form $H_p$, but for specific scenarios, properties of tests of such hypotheses can be established using results in this paper.

The most basic permutation test rejects $H_p$ when $T(X) > T^{(k)}(X)$, where
\[
T^{(1)}(X) \leq \cdots \leq T^{(#G)}(X)
\]
are the sorted test statistics $T(gX)$, $g \in G$, and $k = \lfloor(1 - \alpha)#G\rfloor$ with $\alpha \in [0, 1)$. As is known and stated in the following theorem, this test has level at most $\alpha$.

\begin{theorem}
Under $H_p$, $P\{T(X) > T^{(k)}(X)\} \leq \alpha$.
\end{theorem}

We now give two proofs: a conditioning-based approach and an approach without conditioning. Both approaches are more or less known. The conditioning-based proof is similar to that in \citet{Pesarin2015}, but the setting is more general. For each $x \in \mathcal{X}$, define $O_x$ to be the orbit of $x$, which is the set $\{gx : g \in G\} \subseteq \mathcal{X}$.

\begin{proof}[Proof of Theorem 1]
Let $A = \{x \in \mathcal{X} : T(x) > T^{(k)}(x)\}$ be the set of elements of the sample space that lead to rejection. Suppose $H_p$ holds. By the group structure, $Gg = G$ for all $g \in G$. Consequently, $T^{(k)}(gX) = T^{(k)}(X)$ for all $g \in G$. Thus, $\#{g \in G : gX \in A} = \#{g \in G : T(gX) > T^{(k)}(gX)\} = \#{g \in G : T(gX) > T^{(k)}(X)\} \leq \alpha#G$.

Endow the space of orbits with the $\sigma$-algebra that it inherits from the $\sigma$-algebra on $\mathcal{X}$. Analogously to the proof of Theorem 15.2.2 in \citet{Lehmann2005}, we obtain
\[
P(X \in A | O_X) = \frac{1}{#G}\#{g \in G : gX \in A}.
\]
By the argument above, this is bounded by $\alpha$. Hence,
\[
P(X \in A) = \mathbb{E}\{P(X \in A | O_X)\} \leq \alpha
\]
as was to be shown.
\end{proof}

We now state a different proof without conditioning. A similar proof can be found in \citet{Hoeffding1952} and \citet{Lehmann2005} (p. 634).

\begin{proof}[Alternative proof of Theorem 1]
By the group structure, $Gg = G$ for all $g \in G$. Hence, $T^{(k)}(gX) = T^{(k)}(X)$ for all $g \in G$. Let $h$ have the uniform distribution on $G$. Then, under $H_p$, the rejection probability is
\[
P\{T(X) > T^{(k)}(X)\} = P\{T(hX) > T^{(k)}(hX)\} = P\{T(hX) > T^{(k)}(X)\}.
\]
The first equality follows from the null hypothesis, and the second equality holds since $T^{(k)}(X) = T^{(k)}(hX)$. Since $h$ is uniform on $G$, the above probability equals
\[
\mathbb{E}\left[(#G)^{-1} \cdot \#{g \in G : T(gX) > T^{(k)}(X)\}\right] \leq \alpha,
\]
as was to be shown.
\end{proof}

The test of Theorem 1 is not always exact. When the data are discrete, then the basic permutation test is often slightly conservative, due to a nonzero probability of tied values in $\mathcal{X}$. Under the following condition, which is often satisfied for continuous data, but usually not for discrete data, the test is exact for certain values of $\alpha$.

\begin{condition}
There is a partition $\{G_1, \ldots, G_m\}$ of $G$ with $\mathrm{id} \in G_1$ and $#G_1 = \cdots = #G_m$, such that under $H_p$ with probability 1 for all $g, g' \in G$, $T(gX) = T(g'X)$ if and only if $g$ and $g'$ are in the same set $G_i$.
\end{condition}

\begin{proposition}
Under Condition 1, the test of Theorem 1 is exact if and only if $\alpha \in \{0, 1/m, \ldots, (m - 1)/m\}$.
\end{proposition}

The proof of this result is analogous to the proof of Theorem 1. As an example where Condition 1 holds, consider a randomized trial where $X \in \mathbb{R}^{2n}$ and the test statistic is
\[
T(X) = \sum_{i=1}^n X\]